[{"title":"VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning","abstract":"Vision-Language Navigation (VLN) is a core challenge in embodied AI,\nrequiring agents to navigate real-world environments using natural language\ninstructions. Current language model-based navigation systems operate on\ndiscrete topological graphs, limiting path planning to predefined node\nconnections. We propose VLN-R1, an end-to-end framework that leverages Large\nVision-Language Models (LVLM) to directly translate egocentric video streams\ninto continuous navigation actions, adopting GRPO-based training inspired by\nDeepSeek-R1. To enable effective training, we first construct the VLN-Ego\ndataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling\nto balance historical and current observations. While large language models can\nsupervise complete textual instructions, they lack fine-grained action-level\ncontrol. Our framework employs a two-stage training approach: a) Supervised\nfine-tuning (SFT) to align the model's action sequence text predictions with\nexpert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced\nwith a Time-Decayed Reward (TDR) mechanism that strategically weights\nmulti-step future actions. Experimental results show VLN-R1 achieves strong\nperformance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied\nnavigation and enhance task-specific reasoning through data-efficient,\nreward-driven post-training.","authors":"Zhangyang Qi, Zhixiong Zhang, Yizhou Yu, Jiaqi Wang, Hengshuang Zhao","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17221v1"},{"title":"Impact of the large-scale cosmic web on the X-ray emitting\n  circumgalactic medium","abstract":"The hot circumgalactic medium (CGM), probed by X-ray observations, plays a\ncentral role in understanding gas flows that drive a galaxy's evolution. While\nCGM properties have been widely studied, the influence of a galaxy's\nlarge-scale cosmic environment on the hot gas content remains less explored. We\ninvestigate how the large-scale cosmic web affects the X-ray surface brightness\n(XSB) profiles of galaxies in the context of cosmological simulations. We use\nour novel IllustrisTNG-based lightcone, spanning $0.03 \\leq z \\leq 0.3$, first\ndeveloped in our previous work, and generate self-consistent mock X-ray\nobservations, using intrinsic gas cell information. We apply the filament\nfinder DisPerSE on the galaxy distributions to identify the cosmic filaments\nwithin the lightcone. We classify central galaxies into five distinct\nlarge-scale environment (LSE) categories: clusters and massive groups, cluster\noutskirts, filaments, filament-void transition regions, and voids\/walls. We\nfind that the X-ray surface brightness profiles (XSB) of central galaxies of\ndark matter halos in filaments with $M_{\\rm 200m} >10^{12}\\ M_\\odot$ are X-ray\nbrighter than those in voids and walls, with $20-45%$ deviations in the radial\nrange of $\\sim (0.3-0.5) R_{\\rm 200m}$. We investigate the source of this\nenhancement and find that the filament galaxies show higher average gas\ndensities, temperatures, and metallicities compared to voids\/walls galaxies.\nOur results demonstrate that the impact of the large-scale cosmic environment\nis imprinted on the hot CGM's X-ray emission. Future theoretical work on\nstudying the effect of assembly history, connectivity, and gas accretion on\ngalaxies in filaments and voids would help to further our understanding of the\nimpact of the environment on X-ray observations.","authors":"Soumya Shreeram, Daniela Gal\u00e1rraga-Espinosa, Johan Comparat, Andrea Merloni, Daisuke Nagai, C\u00e9line Peroux, Ilaria Marini, C\u00e9line Gouin, Kirpal Nandra, Yi Zhang, Gabriele Ponti, Anna Olechowska","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17222v1"},{"title":"Emergent Temporal Correspondences from Video Diffusion Transformers","abstract":"Recent advancements in video diffusion models based on Diffusion Transformers\n(DiTs) have achieved remarkable success in generating temporally coherent\nvideos. Yet, a fundamental question persists: how do these models internally\nestablish and represent temporal correspondences across frames? We introduce\nDiffTrack, the first quantitative analysis framework designed to answer this\nquestion. DiffTrack constructs a dataset of prompt-generated video with pseudo\nground-truth tracking annotations and proposes novel evaluation metrics to\nsystematically analyze how each component within the full 3D attention\nmechanism of DiTs (e.g., representations, layers, and timesteps) contributes to\nestablishing temporal correspondences. Our analysis reveals that query-key\nsimilarities in specific, but not all, layers play a critical role in temporal\nmatching, and that this matching becomes increasingly prominent during the\ndenoising process. We demonstrate practical applications of DiffTrack in\nzero-shot point tracking, where it achieves state-of-the-art performance\ncompared to existing vision foundation and self-supervised video models.\nFurther, we extend our findings to motion-enhanced video generation with a\nnovel guidance method that improves temporal consistency of generated videos\nwithout additional training. We believe our work offers crucial insights into\nthe inner workings of video DiTs and establishes a foundation for further\nresearch and applications leveraging their temporal understanding.","authors":"Jisu Nam, Soowon Son, Dahyun Chung, Jiyoung Kim, Siyoon Jin, Junhwa Hur, Seungryong Kim","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17220v1"},{"title":"No Free Lunch: Rethinking Internal Feedback for LLM Reasoning","abstract":"Reinforcement learning has emerged as a powerful paradigm for post-training\nlarge language models (LLMs) to improve reasoning. Approaches like\nReinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning\nwith Verifiable Rewards (RLVR) have shown strong results, but they require\nextensive external supervision. We investigate an alternative class of methods,\nReinforcement Learning from Internal Feedback (RLIF), which relies solely on\nintrinsic model-derived signals instead of external rewards. In particular, we\nleverage unsupervised reward proxies such as token-level entropy,\ntrajectory-level entropy, and self-certainty. Our theoretical analysis shows\nthese internal objectives are partially equivalent, and we empirically evaluate\nvarious RLIF strategies on challenging math reasoning benchmarks. Experimental\nresults demonstrate that RLIF can boost the reasoning performance of base LLMs\nat the beginning phase of the training, matching or surpassing RLVR techniques\non these tasks. However, when training progresses, performance degrades even\nbelow the model before training. Moreover, we find that RLIF yields little\nimprovement for instruction-tuned models, indicating diminishing returns of\nintrinsic feedback once an LLM is already instruction-tuned. We further analyze\nthis limitation by mixing model weights and explain the reason of RLIF's\ntraining behaviors, providing practical guidelines for integrating internal\nfeedback signals into LLM training. We hope our analysis of internal feedback\nwill inform more principled and effective strategies for LLM post-training.","authors":"Yanzhi Zhang, Zhaoxi Zhang, Haoxiang Guan, Yilin Cheng, Yitong Duan, Chen Wang, Yue Wang, Shuxin Zheng, Jiyan He","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17219v1"},{"title":"Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual\n  Tokens","abstract":"Vision-language models (VLMs) excel at multimodal understanding, yet their\ntext-only decoding forces them to verbalize visual reasoning, limiting\nperformance on tasks that demand visual imagination. Recent attempts train VLMs\nto render explicit images, but the heavy image-generation pre-training often\nhinders the reasoning ability. Inspired by the way humans reason with mental\nimagery-the internal construction and manipulation of visual cues-we\ninvestigate whether VLMs can reason through interleaved multimodal trajectories\nwithout producing explicit images. To this end, we present a Machine Mental\nImagery framework, dubbed as Mirage, which augments VLM decoding with latent\nvisual tokens alongside ordinary text. Concretely, whenever the model chooses\nto ``think visually'', it recasts its hidden states as next tokens, thereby\ncontinuing a multimodal trajectory without generating pixel-level images. Begin\nby supervising the latent tokens through distillation from ground-truth image\nembeddings, we then switch to text-only supervision to make the latent\ntrajectory align tightly with the task objective. A subsequent reinforcement\nlearning stage further enhances the multimodal reasoning capability.\nExperiments on diverse benchmarks demonstrate that Mirage unlocks stronger\nmultimodal reasoning without explicit image generation.","authors":"Zeyuan Yang, Xueyang Yu, Delin Chen, Maohao Shen, Chuang Gan","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17218v1"},{"title":"Bias hardened estimators of patchy screening profiles","abstract":"Detecting anisotropic screening of the cosmic microwave background (CMB)\nholds the promise of revealing the distribution of gas in the Universe,\ncharacterizing the complex processes of galaxy formation and feedback, and\nstudying the epoch of reionization. Estimators for inhomogeneous screening,\nincluding some recently proposed small-scale (stacked) estimators, are\nquadratic or higher order in the CMB temperature or polarization fields and are\ntherefore subject to contamination from CMB lensing. We review the origin of\nthis lensing bias and show that, when stacking on unWISE galaxies, the expected\nlensing bias dominates the signal if left unmitigated. Hardening techniques\nthat null the lensing bias have been proposed for standard quadratic\nestimators, whereas only approximate methods have been proposed for stacked\nestimators. We review these techniques and apply the former to stacked\nestimators, presenting several strategies (including the optimal strategy) to\nnull lensing contamination when stacking on any large-scale structure (LSS)\ntracer.","authors":"Noah Sailer, Boryana Hadzhiyska, Simone Ferraro","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17217v1"},{"title":"Hierarchical constraints on gravitational waves from horizonless compact\n  objects","abstract":"We use the data of several promising gravitational wave observations to\nobtain increasingly stringent bounds on near-horizon deviations of their\nsources from the Kerr geometry. A range of horizonless compact objects proposed\nas alternatives to black holes of general relativity would possess a modified\ngravitational wave emission after the merger. Modelling these objects by\nintroducing reflection of gravitational waves near the horizon, we can measure\ndeviations from Kerr in terms of a single additional parameter, the location of\nthe reflection. We quote bounds on deviations for 5 events in addition to\nprevious results obtained for GW150914. Additionally, we improve upon previous\nresults by hierarchically combining information from all analysed events,\nyielding a bound on deviations of less than $1.3 \\times 10^{-26}$ meters above\nthe horizon.","authors":"Rajrupa Mondal, Julian Westerweck, Yotam Sherf, Collin D. Capano","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17215v1"},{"title":"Long-term Traffic Simulation with Interleaved Autoregressive Motion and\n  Scenario Generation","abstract":"An ideal traffic simulator replicates the realistic long-term point-to-point\ntrip that a self-driving system experiences during deployment. Prior models and\nbenchmarks focus on closed-loop motion simulation for initial agents in a\nscene. This is problematic for long-term simulation. Agents enter and exit the\nscene as the ego vehicle enters new regions. We propose InfGen, a unified\nnext-token prediction model that performs interleaved closed-loop motion\nsimulation and scene generation. InfGen automatically switches between\nclosed-loop motion simulation and scene generation mode. It enables stable\nlong-term rollout simulation. InfGen performs at the state-of-the-art in\nshort-term (9s) traffic simulation, and significantly outperforms all other\nmethods in long-term (30s) simulation. The code and model of InfGen will be\nreleased at https:\/\/orangesodahub.github.io\/InfGen","authors":"Xiuyu Yang, Shuhan Tan, Philipp Kr\u00e4henb\u00fchl","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17213v1"},{"title":"Regularized Targeted Maximum Likelihood Estimation in Highly Adaptive\n  Lasso Implied Working Models","abstract":"We address the challenge of performing Targeted Maximum Likelihood Estimation\n(TMLE) after an initial Highly Adaptive Lasso (HAL) fit. Existing approaches\nthat utilize the data-adaptive working model selected by HAL-such as the\nrelaxed HAL update-can be simple and versatile but may become computationally\nunstable when the HAL basis expansions introduce collinearity. Undersmoothed\nHAL may fail to solve the efficient influence curve (EIC) at the desired level\nwithout overfitting, particularly in complex settings like survival-curve\nestimation. A full HAL-TMLE, which treats HAL as the initial estimator and then\ntargets in the nonparametric or semiparametric model, typically demands costly\niterative clever-covariate calculations in complex set-ups like survival\nanalysis and longitudinal mediation analysis. To overcome these limitations, we\npropose two new HAL-TMLEs that operate within the finite-dimensional working\nmodel implied by HAL: Delta-method regHAL-TMLE and Projection-based\nregHAL-TMLE. We conduct extensive simulations to demonstrate the performance of\nour proposed methods.","authors":"Yi Li, Sky Qiu, Zeyi Wang, Mark van der Laan","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17214v1"},{"title":"Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D\n  Gaussian Splatting","abstract":"Articulated objects are common in the real world, yet modeling their\nstructure and motion remains a challenging task for 3D reconstruction methods.\nIn this work, we introduce Part$^{2}$GS, a novel framework for modeling\narticulated digital twins of multi-part objects with high-fidelity geometry and\nphysically consistent articulation. Part$^{2}$GS leverages a part-aware 3D\nGaussian representation that encodes articulated components with learnable\nattributes, enabling structured, disentangled transformations that preserve\nhigh-fidelity geometry. To ensure physically consistent motion, we propose a\nmotion-aware canonical representation guided by physics-based constraints,\nincluding contact enforcement, velocity consistency, and vector-field\nalignment. Furthermore, we introduce a field of repel points to prevent part\ncollisions and maintain stable articulation paths, significantly improving\nmotion coherence over baselines. Extensive evaluations on both synthetic and\nreal-world datasets show that Part$^{2}$GS consistently outperforms\nstate-of-the-art methods by up to 10$\\times$ in Chamfer Distance for movable\nparts.","authors":"Tianjiao Yu, Vedant Shah, Muntasir Wahed, Ying Shen, Kiet A. Nguyen, Ismini Lourentzou","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17212v1"},{"title":"BREAD: Branched Rollouts from Expert Anchors Bridge SFT & RL for\n  Reasoning","abstract":"Small language models (SLMs) struggle to learn complex reasoning behaviors,\nespecially when high-quality traces are scarce or difficult to learn from. The\nstandard training approach combines a supervised fine-tuning (SFT) stage, often\nto distill capabilities of a larger model, followed by a reinforcement learning\n(RL)stage such as Group Relative Policy Optimization (GRPO). In this paper, we\ninvestigate the fundamental limitations of this SFT + RL paradigm and propose\nmethods to overcome them. Under a suitable theoretical model, we demonstrate\nthat the SFT + RL strategy can fail completely when (1) the expert's traces are\ntoo difficult for the small model to express, or (2) the small model's\ninitialization has exponentially small likelihood of success. To address these,\nwe introduce BREAD: a GRPO variant that unifies the SFT and RL stages via\npartial expert guidance and branched rollouts. When self-generated traces fail,\nBREAD adaptively inserts short expert prefixes\/hints, allowing the small model\nto complete the rest of the reasoning path, and ensuring that each update\nincludes at least one successful trace. This mechanism both densifies the\nreward signal and induces a natural learning curriculum. BREAD requires fewer\nthan 40% of ground-truth traces, consistently outperforming standard GRPO while\nspeeding up the training by about 3 times. Importantly, we demonstrate that\nBREAD helps the model solve problems that are otherwise unsolvable by the SFT +\nRL strategy, highlighting how branched rollouts and expert guidance can\nsubstantially boost SLM reasoning.","authors":"Xuechen Zhang, Zijian Huang, Yingcong Li, Chenshun Ni, Jiasi Chen, Samet Oymak","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17211v1"},{"title":"Lower Bounds against the Ideal Proof System in Finite Fields","abstract":"Lower bounds against strong algebraic proof systems and specifically\nfragments of the Ideal Proof System (IPS), have been obtained in an ongoing\nline of work. All of these bounds, however, are proved only over large (or\ncharacteristic $0$) fields, yet finite fields are the more natural setting for\npropositional proof complexity, especially for progress toward lower bounds for\nFrege systems such as $AC^0[p]$-Frege. This work establishes lower bounds\nagainst fragments of IPS over fixed finite fields. Specifically, we show that a\nvariant of the knapsack instance studied by Govindasamy, Hakoniemi, and\nTzameret (FOCS'22) has no polynomial-size IPS refutation over finite fields\nwhen the refutation is multilinear and written as a constant-depth circuit. The\nkey ingredient of our argument is the recent set-multilinearization result of\nForbes (CCC'24), which extends the earlier result of Limaye, Srinivasan, and\nTavenas (FOCS'21) to all fields, and an extension of the techniques of\nGovindasamy, Hakoniemi, and Tzameret to finite fields. We also separate this\nproof system from the one studied by Govindasamy, Hakoniemi, and Tzameret.\n  In addition, we present new lower bounds for read-once algebraic branching\nprogram refutations, roABP-IPS, in finite fields, extending results of Forbes,\nShpilka, Tzameret, and Wigderson (Theor. of Comput.'21) and Hakoniemi, Limaye,\nand Tzameret (STOC'24).\n  Finally, we show that any lower bound against any proof system at least as\nstrong as (non-multilinear) constant-depth IPS over finite fields for any\ninstance, even a purely algebraic instance (i.e., not a translation of a\nBoolean formula or CNF), implies a hard CNF formula for the respective IPS\nfragment, and hence an $AC^0[p]$-Frege lower bound by known simulations over\nfinite fields (Grochow and Pitassi (J. ACM'18)).","authors":"Tal Elbaz, Nashlen Govindasamy, Jiaqi Lu, Iddo Tzameret","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17210v1"},{"title":"Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency","abstract":"Fine-tuning a general-purpose large language model (LLM) for a specific\ndomain or task has become a routine procedure for ordinary users. However,\nfine-tuning is known to remove the safety alignment features of the model, even\nwhen the fine-tuning data does not contain any harmful content. We consider\nthis to be a critical failure mode of LLMs due to the widespread uptake of\nfine-tuning, combined with the benign nature of the \"attack\". Most\nwell-intentioned developers are likely unaware that they are deploying an LLM\nwith reduced safety. On the other hand, this known vulnerability can be easily\nexploited by malicious actors intending to bypass safety guardrails. To make\nany meaningful progress in mitigating this issue, we first need reliable and\nreproducible safety evaluations. In this work, we investigate how robust a\nsafety benchmark is to trivial variations in the experimental procedure, and\nthe stochastic nature of LLMs. Our initial experiments expose surprising\nvariance in the results of the safety evaluation, even when seemingly\ninconsequential changes are made to the fine-tuning setup. Our observations\nhave serious implications for how researchers in this field should report\nresults to enable meaningful comparisons in the future.","authors":"Kathleen C. Fraser, Hillary Dawkins, Isar Nejadgholi, Svetlana Kiritchenko","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17209v1"},{"title":"Dissecting the SWE-Bench Leaderboards: Profiling Submitters and\n  Architectures of LLM- and Agent-Based Repair Systems","abstract":"The rapid progress in Automated Program Repair (APR) has been driven by\nadvances in AI, particularly large language models (LLMs) and agent-based\nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\nsystems using real issues and pull requests mined from 12 popular open-source\nPython repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench\nVerified, have become central platforms for tracking progress and comparing\nsolutions. However, because the submission process does not require detailed\ndocumentation, the architectural design and origin of many solutions remain\nunclear. In this paper, we present the first comprehensive study of all\nsubmissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)\nleaderboards, analyzing 67 unique approaches across dimensions such as\nsubmitter type, product availability, LLM usage, and system architecture. Our\nfindings reveal the dominance of proprietary LLMs (especially Claude 3.5\/3.7),\nthe presence of both agentic and non-agentic designs, and a contributor base\nspanning from individual developers to large tech companies.","authors":"Matias Martinez, Xavier Franch","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17208v1"},{"title":"High-precision Quantum Phase Estimation on a Trapped-ion Quantum\n  Computer","abstract":"Emergent quantum computing technologies are widely expected to provide novel\napproaches in the simulation of quantum chemistry. Despite rapid improvements\nin the scale and fidelity of quantum computers, high resource requirements make\nthe execution of quantum chemistry experiments challenging. Typical experiments\nare limited in the number of qubits used, incur a substantial shot cost, or\nrequire complex architecture-specific optimization and error mitigation\ntechniques. In this paper, we propose a conceptually simple benchmarking\napproach involving the use of multi-ancilla quantum phase estimation. Our\napproach is restricted to very small chemical systems, and does not scale\nfavorably beyond molecular systems that can be described with $2$ qubits;\nhowever, this restriction allows us to generate circuits that scale\nquadratically in gate count with the number of qubits in the readout register.\nThis enables the execution of quantum chemistry circuits that act on many\nqubits, while producing meaningful results with limited shot counts. We use\nthis technique (with $200$ shots per experiment) to calculate the ground state\nenergy of molecular hydrogen to $50$ bits of precision ($8.9 \\times 10^{-16}$\nhartree) on a $56$-qubit trapped-ion quantum computer, negating Trotter error.\nIncluding Trotter error, we obtain between $32$ and $36$ bits of precision\n($1.5 * 10^{-10}$ and $6.0 * 10^{-11}$ hartree respectively), vastly exceeding\nchemical accuracy ($1.6 * 10^{-3}$ hartree) against Full Configuration\nInteraction. We consider application of the approach to deeper circuits, and\ndiscuss potential as a benchmark task for near-term quantum devices.","authors":"Andrew Tranter, Duncan Gowland, Kentaro Yamamoto, Michelle Sze, David Mu\u00f1oz Ramo","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17207v1"},{"title":"DreamCube: 3D Panorama Generation via Multi-plane Synchronization","abstract":"3D panorama synthesis is a promising yet challenging task that demands\nhigh-quality and diverse visual appearance and geometry of the generated\nomnidirectional content. Existing methods leverage rich image priors from\npre-trained 2D foundation models to circumvent the scarcity of 3D panoramic\ndata, but the incompatibility between 3D panoramas and 2D single views limits\ntheir effectiveness. In this work, we demonstrate that by applying multi-plane\nsynchronization to the operators from 2D foundation models, their capabilities\ncan be seamlessly extended to the omnidirectional domain. Based on this design,\nwe further introduce DreamCube, a multi-plane RGB-D diffusion model for 3D\npanorama generation, which maximizes the reuse of 2D foundation model priors to\nachieve diverse appearances and accurate geometry while maintaining multi-view\nconsistency. Extensive experiments demonstrate the effectiveness of our\napproach in panoramic image generation, panoramic depth estimation, and 3D\nscene generation.","authors":"Yukun Huang, Yanning Zhou, Jianan Wang, Kaiyi Huang, Xihui Liu","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17206v1"},{"title":"Efficient Implementation of Multi-sensor Adaptive Birth Samplers for\n  Labeled Random Finite Set Tracking","abstract":"Adaptive track initiation remains a crucial component of many modern\nmulti-target tracking systems. For labeled random finite sets multi-object\nfilters, prior work has been established to construct a labeled multi-object\nbirth density using measurements from multiple sensors. A naive construction of\nthis adaptive birth set density results in an exponential number of newborn\ncomponents in the number of sensors. A truncation procedure was provided that\nleverages a Gibbs sampler to truncate the birth density, reducing the\ncomplexity to quadratic in the number of sensors. However, only a limited\ndiscussion has been provided on additional algorithmic techniques that can be\nemployed to substantially reduce the complexity in practical tracking\napplications. In this paper, we propose five efficiency enhancements for the\nlabeled random finite sets multi-sensor adaptive birth procedure. Simulation\nresults are provided to demonstrate their computational benefits and show that\nthey result in a negligible change to the multi-target tracking performance.","authors":"Jennifer Bondarchuk, Anthony Trezza, Donald J. Bucci Jr","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17205v1"},{"title":"Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement\n  Learning","abstract":"Effectively scaling up deep reinforcement learning models has proven\nnotoriously difficult due to network pathologies during training, motivating\nvarious targeted interventions such as periodic reset and architectural\nadvances such as layer normalization. Instead of pursuing more complex\nmodifications, we show that introducing static network sparsity alone can\nunlock further scaling potential beyond their dense counterparts with\nstate-of-the-art architectures. This is achieved through simple one-shot random\npruning, where a predetermined percentage of network weights are randomly\nremoved once before training. Our analysis reveals that, in contrast to naively\nscaling up dense DRL networks, such sparse networks achieve both higher\nparameter efficiency for network expressivity and stronger resistance to\noptimization challenges like plasticity loss and gradient interference. We\nfurther extend our evaluation to visual and streaming RL scenarios,\ndemonstrating the consistent benefits of network sparsity.","authors":"Guozheng Ma, Lu Li, Zilin Wang, Li Shen, Pierre-Luc Bacon, Dacheng Tao","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17204v1"},{"title":"Confidence Scoring for LLM-Generated SQL in Supply Chain Data Extraction","abstract":"Large Language Models (LLMs) have recently enabled natural language\ninterfaces that translate user queries into executable SQL, offering a powerful\nsolution for non-technical stakeholders to access structured data. However, one\nof the limitation that LLMs do not natively express uncertainty makes it\ndifficult to assess the reliability of their generated queries. This paper\npresents a case study that evaluates multiple approaches to estimate confidence\nscores for LLM-generated SQL in supply chain data retrieval. We investigated\nthree strategies: (1) translation-based consistency checks; (2) embedding-based\nsemantic similarity between user questions and generated SQL; and (3)\nself-reported confidence scores directly produced by the LLM. Our findings\nreveal that LLMs are often overconfident in their own outputs, which limits the\neffectiveness of self-reported confidence. In contrast, embedding-based\nsimilarity methods demonstrate strong discriminative power in identifying\ninaccurate SQL.","authors":"Jiekai Ma, Yikai Zhao","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17203v1"},{"title":"UniFork: Exploring Modality Alignment for Unified Multimodal\n  Understanding and Generation","abstract":"Unified image understanding and generation has emerged as a promising\nparadigm in multimodal artificial intelligence. Despite recent progress, the\noptimal architectural design for such unified models remains an open challenge.\nIn this work, we start by analyzing the modality alignment behaviors of\ntask-specific expert models for understanding and generation, as well as\ncurrent unified models. Our analysis reveals a crucial observation:\nunderstanding tasks benefit from a progressively increasing modality alignment\nacross network depth, which helps build up semantic information for better\ncomprehension; In contrast, generation tasks follow a different trend: modality\nalignment increases in the early layers but decreases in the deep layers to\nrecover spatial details. These divergent alignment patterns create a\nfundamental conflict in fully shared Transformer backbones, where a uniform\nrepresentational flow often leads to performance compromises across two tasks.\nMotivated by this finding, we introduce UniFork, a novel Y-shaped architecture\nthat shares the shallow layers for cross-task representation learning, while\nemploying task-specific branches in deeper layers to avoid task interference.\nThis design effectively balances shared learning and task specialization.\nThrough extensive ablation experiments, we demonstrate that Unifork\nconsistently outperforms conventional fully shared Transformer architectures,\nand achieves performance on par with or better than task-specific models.","authors":"Teng Li, Quanfeng Lu, Lirui Zhao, Hao Li, Xizhou Zhu, Yu Qiao, Jun Zhang, Wenqi Shao","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17202v1"},{"title":"Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with\n  Hybrid History Condition","abstract":"Recent advances in diffusion-based and controllable video generation have\nenabled high-quality and temporally coherent video synthesis, laying the\ngroundwork for immersive interactive gaming experiences. However, current\nmethods face limitations in dynamics, generality, long-term consistency, and\nefficiency, which limit the ability to create various gameplay videos. To\naddress these gaps, we introduce Hunyuan-GameCraft, a novel framework for\nhigh-dynamic interactive video generation in game environments. To achieve\nfine-grained action control, we unify standard keyboard and mouse inputs into a\nshared camera representation space, facilitating smooth interpolation between\nvarious camera and movement operations. Then we propose a hybrid\nhistory-conditioned training strategy that extends video sequences\nautoregressively while preserving game scene information. Additionally, to\nenhance inference efficiency and playability, we achieve model distillation to\nreduce computational overhead while maintaining consistency across long\ntemporal sequences, making it suitable for real-time deployment in complex\ninteractive environments. The model is trained on a large-scale dataset\ncomprising over one million gameplay recordings across over 100 AAA games,\nensuring broad coverage and diversity, then fine-tuned on a carefully annotated\nsynthetic dataset to enhance precision and control. The curated game scene data\nsignificantly improves the visual fidelity, realism and action controllability.\nExtensive experiments demonstrate that Hunyuan-GameCraft significantly\noutperforms existing models, advancing the realism and playability of\ninteractive game video generation.","authors":"Jiaqi Li, Junshu Tang, Zhiyong Xu, Longhuang Wu, Yuan Zhou, Shuai Shao, Tianbao Yu, Zhiguo Cao, Qinglin Lu","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17201v1"},{"title":"Intelligent Reflecting Surfaces for THz Communications: Fundamentals,\n  Key Solutions, and System Prototyping","abstract":"Intelligent reflecting surfaces (IRSs) have emerged as a cost-effective\ntechnology for terahertz (THz) communications by enabling programmable control\nof the wireless environment. This paper provides a comprehensive overview of\nIRSs-aided THz communications, covering hardware designs, advanced signal\nprocessing techniques, and practical deployment strategies. It first examines\nkey THz reconfigurable metasurface architectures, including electronic,\noptical, phase-change material, and micro-electromechanical systems\n(MEMS)-based implementations, highlighting their reconfiguration mechanisms and\nchallenges. Then, fundamental effects including near field and beam squint in\nwideband THz systems are analyzed, along with their impacts on system\nperformance. The paper further explores conventional and beam-squint-assisted\nchannel estimation methods, innovative beam management strategies, and\ndeployment considerations across large- and small-scale scenarios. Practical\nexperiments at 220 gigahertz (GHz) validate the effectiveness of IRS in\nimproving signal strength and communication reliability for both single-user\nand multi-user setups.","authors":"Qingqing Wu, Yanze Zhu, Qiaoyan Peng, Wanming Hao, Yanzhao Hou, Fengyuan Yang, Wencai Yan, Guoning Wang, Wen Chen, Chi Qiu","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17200v1"},{"title":"Tighter Error Bounds for the qDRIFT Algorithm","abstract":"Randomized algorithms such as qDRIFT provide an efficient framework for\nquantum simulation by sampling terms from a decomposition of the system's\ngenerator. However, existing error bounds for qDRIFT scale quadratically with\nthe norm of the generator, limiting their efficiency for large-scale closed or\nopen quantum system simulation. In this work, we refine the qDRIFT error bound\nby incorporating Jensen's inequality and a careful treatment of the integral\nform of the error. This yields an improved scaling that significantly reduces\nthe number of steps required to reach a fixed simulation accuracy. Our result\napplies to both closed and open quantum systems, and we explicitly recover the\nimproved bound in the Hamiltonian case. To demonstrate the practical impact of\nthis refinement, we apply it to three settings: quantum chemistry simulations,\ndissipative transverse field Ising models, and Hamiltonian encoding of\nclassical data for quantum machine learning. In each case, our bound leads to a\nsubstantial reduction in gate counts, highlighting its broad utility in\nenhancing randomized simulation techniques.","authors":"I. J. David, I. Sinayskiy, F. Petruccione","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17199v1"},{"title":"Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation","abstract":"Generating large-scale demonstrations for dexterous hand manipulation remains\nchallenging, and several approaches have been proposed in recent years to\naddress this. Among them, generative models have emerged as a promising\nparadigm, enabling the efficient creation of diverse and physically plausible\ndemonstrations. In this paper, we introduce Dex1B, a large-scale, diverse, and\nhigh-quality demonstration dataset produced with generative models. The dataset\ncontains one billion demonstrations for two fundamental tasks: grasping and\narticulation. To construct it, we propose a generative model that integrates\ngeometric constraints to improve feasibility and applies additional conditions\nto enhance diversity. We validate the model on both established and newly\nintroduced simulation benchmarks, where it significantly outperforms prior\nstate-of-the-art methods. Furthermore, we demonstrate its effectiveness and\nrobustness through real-world robot experiments. Our project page is at\nhttps:\/\/jianglongye.com\/dex1b","authors":"Jianglong Ye, Keyi Wang, Chengjing Yuan, Ruihan Yang, Yiquan Li, Jiyue Zhu, Yuzhe Qin, Xueyan Zou, Xiaolong Wang","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17198v1"},{"title":"Schr\u00f6dinger Bridge Matching for Tree-Structured Costs and Entropic\n  Wasserstein Barycentres","abstract":"Recent advances in flow-based generative modelling have provided scalable\nmethods for computing the Schr\\\"odinger Bridge (SB) between distributions, a\ndynamic form of entropy-regularised Optimal Transport (OT) for the quadratic\ncost. The successful Iterative Markovian Fitting (IMF) procedure solves the SB\nproblem via sequential bridge-matching steps, presenting an elegant and\npractical approach with many favourable properties over the more traditional\nIterative Proportional Fitting (IPF) procedure. Beyond the standard setting,\noptimal transport can be generalised to the multi-marginal case in which the\nobjective is to minimise a cost defined over several marginal distributions. Of\nparticular importance are costs defined over a tree structure, from which\nWasserstein barycentres can be recovered as a special case. In this work, we\nextend the IMF procedure to solve for the tree-structured SB problem. Our\nresulting algorithm inherits the many advantages of IMF over IPF approaches in\nthe tree-based setting. In the specific case of Wasserstein barycentres, our\napproach can be viewed as extending fixed-point approaches for barycentre\ncomputation to the case of flow-based entropic OT solvers.","authors":"Samuel Howard, Peter Potaptchik, George Deligiannidis","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17197v1"},{"title":"Detecting LLM-Generated Short Answers and Effects on Learner Performance","abstract":"The increasing availability of large language models (LLMs) has raised\nconcerns about their potential misuse in online learning. While tools for\ndetecting LLM-generated text exist and are widely used by researchers and\neducators, their reliability varies. Few studies have compared the accuracy of\ndetection methods, defined criteria to identify content generated by LLM, or\nevaluated the effect on learner performance from LLM misuse within learning. In\nthis study, we define LLM-generated text within open responses as those\nproduced by any LLM without paraphrasing or refinement, as evaluated by human\ncoders. We then fine-tune GPT-4o to detect LLM-generated responses and assess\nthe impact on learning from LLM misuse. We find that our fine-tuned LLM\noutperforms the existing AI detection tool GPTZero, achieving an accuracy of\n80% and an F1 score of 0.78, compared to GPTZero's accuracy of 70% and macro F1\nscore of 0.50, demonstrating superior performance in detecting LLM-generated\nresponses. We also find that learners suspected of LLM misuse in the open\nresponse question were more than twice as likely to correctly answer the\ncorresponding posttest MCQ, suggesting potential misuse across both question\ntypes and indicating a bypass of the learning process. We pave the way for\nfuture work by demonstrating a structured, code-based approach to improve\nLLM-generated response detection and propose using auxiliary statistical\nindicators such as unusually high assessment scores on related tasks,\nreadability scores, and response duration. In support of open science, we\ncontribute data and code to support the fine-tuning of similar models for\nsimilar use cases.","authors":"Shambhavi Bhushan, Danielle R Thomas, Conrad Borchers, Isha Raghuvanshi, Ralph Abboud, Erin Gatz, Shivang Gupta, Kenneth Koedinger","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17196v1"},{"title":"Operation and performance of the CMS silicon strip tracker with\n  proton-proton collisions at the CERN LHC","abstract":"Salient aspects of the commissioning, calibration, and performance of the CMS\nsilicon strip tracker are discussed, drawing on experience during operation\nwith proton-proton collisions delivered by the CERN LHC. The data were obtained\nwith a variety of luminosities. The operating temperature of the strip tracker\nwas changed several times during this period and results are shown as a\nfunction of temperature in several cases. Details of the system performance are\npresented, including occupancy, signal-to-noise ratio, Lorentz angle, and\nsingle-hit spatial resolution. Saturation effects in the APV25 readout chip\npreamplifier observed during early Run 2 are presented, showing the effect on\nvarious observables and the subsequent remedy. Studies of radiation effects on\nthe strip tracker are presented both for the optical readout links and the\nsilicon sensors. The observed effects are compared to simulation, where\navailable, and they generally agree well with expectations.","authors":"CMS Collaboration","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17195v1"},{"title":"Any nonincreasing convergence curves are simultaneously possible for\n  GMRES and weighted GMRES, as well as for left and right preconditioned GMRES","abstract":"The convergence of the GMRES linear solver is notoriously hard to predict. A\nparticularly enlightening result by [Greenbaum, Pt\\'ak, Strako\\v{s}, 1996] is\nthat, given any convergence curve, one can build a linear system for which\nGMRES realizes that convergence curve. What is even more extraordinary is that\nthe eigenvalues of the problem matrix can be chosen arbitrarily. We build upon\nthis idea to derive novel results about weighted GMRES. We prove that for any\nlinear system and any prescribed convergence curve, there exists a weight\nmatrix M for which weighted GMRES (i.e., GMRES in the inner product induced by\nM) realizes that convergence curve, and we characterize the form of M.\nAdditionally, we exhibit a necessary and sufficient condition on M for the\nsimultaneous prescription of two convergence curves, one realized by GMRES in\nthe Euclidean inner product, and the other in the inner product induced by M.\nThese results are then applied to infer some properties of preconditioned GMRES\nwhen the preconditioner is applied either on the left or on the right. For\ninstance, we show that any two convergence curves are simultaneously possible\nfor left and right preconditioned GMRES.","authors":"Pierre Matalon, Nicole Spillane","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17193v1"},{"title":"Gravitational lensing observables in stationary and axisymmetric\n  solutions in general relativity","abstract":"We investigate light propagation in self-gravitating systems composed of an\naxially symmetric, stationary, rotating dust fluid. These configurations are\nintrinsically relativistic, sustained entirely by their rotation, since no\ncompact or finite dust distribution can exist under the same symmetry\nconditions in Newtonian gravity. In such systems, rotational effects arise from\noff-diagonal components of the spacetime metric, which are not negligible\ncompared to their Newtonian counterparts. We analyze how these components\naffect the deflection angle of light, showing that they can be interpreted as\ncontributing an additional effective mass. Moreover, their presence can, in\nprinciple, be detected through the characteristic asymmetry they induce in the\nimages of background sources.","authors":"Matteo Luca Ruggiero, Davide Astesiano","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17192v1"},{"title":"Comparison of spin-qubit architectures for quantum error-correcting\n  codes","abstract":"We investigate the performance of two quantum error-correcting codes, the\nsurface code and the Bacon-Shor code, for implementation with spin qubits in\nsilicon. In each case, we construct a logical qubit using a planar array of\nquantum dots, exploring two encoding schemes: one based solely on\nsingle-electron Zeeman qubits (Loss-DiVincenzo qubits), and a hybrid approach\ncombining Zeeman and singlet-triplet qubits. For both codes, we evaluate key\nperformance metrics, including logical state preparation fidelity and\ncycle-level error correction performance, using state-of-the-art experimental\nparameters. Our results show that the hybrid encoding consistently outperforms\nthe pure Zeeman-qubit implementation. By identifying the dominant error\nmechanisms that limit quantum error correction performance, our study\nhighlights concrete targets for improving spin qubit hardware and provides a\npath toward scalable fault-tolerant architectures. In particular, we find that\nthe logical error rate is not limited by memory errors, but rather by gate\nerrors, especially 1- and 2-qubit gate errors.","authors":"Mauricio Guti\u00e9rrez, Juan S. Rojas-Arias, David Obando, Chien-Yuan Chang","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17190v1"},{"title":"On Energy-Efficient Passive Beamforming Design of RIS-Assisted CoMP-NOMA\n  Networks","abstract":"This paper investigates the synergistic potential of reconfigurable\nintelligent surfaces (RIS) and non-orthogonal multiple access (NOMA) to enhance\nthe energy efficiency and performance of next-generation wireless networks. We\ndelve into the design of energy-efficient passive beamforming (PBF) strategies\nwithin RIS-assisted coordinated multi-point (CoMP)-NOMA networks. Two distinct\nRIS configurations, namely, enhancement-only PBF (EO) and enhancement &\ncancellation PBF (EC), are proposed and analyzed. Our findings demonstrate that\nRIS-assisted CoMP-NOMA networks offer significant efficiency gains compared to\ntraditional CoMP-NOMA systems. Furthermore, we formulate a PBF design problem\nto optimize the RIS phase shifts for maximizing energy efficiency. Our results\nreveal that the optimal PBF design is contingent upon several factors,\nincluding the number of cooperating base stations (BSs), the number of RIS\nelements deployed, and the RIS configuration. This study underscores the\npotential of RIS-assisted CoMP-NOMA networks as a promising solution for\nachieving superior energy efficiency and overall performance in future wireless\nnetworks.","authors":"Muhammad Umer, Muhammad Ahmed Mohsin, Aamir Mahmood, Haejoon Jung, Haris Pervaiz, Mikael Gidlund, Syed Ali Hassan","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17189v1"},{"title":"Towards AI Search Paradigm","abstract":"In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint\nfor next-generation search systems capable of emulating human information\nprocessing and decision-making. The paradigm employs a modular architecture of\nfour LLM-powered agents (Master, Planner, Executor and Writer) that dynamically\nadapt to the full spectrum of information needs, from simple factual queries to\ncomplex multi-stage reasoning tasks. These agents collaborate dynamically\nthrough coordinated workflows to evaluate query complexity, decompose problems\ninto executable plans, and orchestrate tool usage, task execution, and content\nsynthesis. We systematically present key methodologies for realizing this\nparadigm, including task planning and tool integration, execution strategies,\naligned and robust retrieval-augmented generation, and efficient LLM inference,\nspanning both algorithmic techniques and infrastructure-level optimizations. By\nproviding an in-depth guide to these foundational components, this work aims to\ninform the development of trustworthy, adaptive, and scalable AI search\nsystems.","authors":"Yuchen Li, Hengyi Cai, Rui Kong, Xinran Chen, Jiamin Chen, Jun Yang, Haojie Zhang, Jiayi Li, Jiayi Wu, Yiqun Chen, Changle Qu, Keyi Kong, Wenwen Ye, Lixin Su, Xinyu Ma, Long Xia, Daiting Shi, Jiashu Zhao, Haoyi Xiong, Shuaiqiang Wang, Dawei Yin","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17188v1"},{"title":"Optimal Implicit Bias in Linear Regression","abstract":"Most modern learning problems are over-parameterized, where the number of\nlearnable parameters is much greater than the number of training data points.\nIn this over-parameterized regime, the training loss typically has infinitely\nmany global optima that completely interpolate the data with varying\ngeneralization performance. The particular global optimum we converge to\ndepends on the implicit bias of the optimization algorithm. The question we\naddress in this paper is, ``What is the implicit bias that leads to the best\ngeneralization performance?\". To find the optimal implicit bias, we provide a\nprecise asymptotic analysis of the generalization performance of interpolators\nobtained from the minimization of convex functions\/potentials for\nover-parameterized linear regression with non-isotropic Gaussian data. In\nparticular, we obtain a tight lower bound on the best generalization error\npossible among this class of interpolators in terms of the\nover-parameterization ratio, the variance of the noise in the labels, the\neigenspectrum of the data covariance, and the underlying distribution of the\nparameter to be estimated. Finally, we find the optimal convex implicit bias\nthat achieves this lower bound under certain sufficient conditions involving\nthe log-concavity of the distribution of a Gaussian convolved with the prior of\nthe true underlying parameter.","authors":"Kanumuri Nithin Varma, Babak Hassibi","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17187v1"},{"title":"YASMOT: Yet another stereo image multi-object tracker","abstract":"There now exists many popular object detectors based on deep learning that\ncan analyze images and extract locations and class labels for occurrences of\nobjects. For image time series (i.e., video or sequences of stills), tracking\nobjects over time and preserving object identity can help to improve object\ndetection performance, and is necessary for many downstream tasks, including\nclassifying and predicting behaviors, and estimating total abundances. Here we\npresent yasmot, a lightweight and flexible object tracker that can process the\noutput from popular object detectors and track objects over time from either\nmonoscopic or stereoscopic camera configurations. In addition, it includes\nfunctionality to generate consensus detections from ensembles of object\ndetectors.","authors":"Ketil Malde","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17186v1"},{"title":"A Common Pool of Privacy Problems: Legal and Technical Lessons from a\n  Large-Scale Web-Scraped Machine Learning Dataset","abstract":"We investigate the contents of web-scraped data for training AI systems, at\nsizes where human dataset curators and compilers no longer manually annotate\nevery sample. Building off of prior privacy concerns in machine learning\nmodels, we ask: What are the legal privacy implications of web-scraped machine\nlearning datasets? In an empirical study of a popular training dataset, we find\nsignificant presence of personally identifiable information despite\nsanitization efforts. Our audit provides concrete evidence to support the\nconcern that any large-scale web-scraped dataset may contain personal data. We\nuse these findings of a real-world dataset to inform our legal analysis with\nrespect to existing privacy and data protection laws. We surface various\nprivacy risks of current data curation practices that may propagate personal\ninformation to downstream models. From our findings, we argue for reorientation\nof current frameworks of \"publicly available\" information to meaningfully limit\nthe development of AI built upon indiscriminate scraping of the internet.","authors":"Rachel Hong, Jevan Hutson, William Agnew, Imaad Huda, Tadayoshi Kohno, Jamie Morgenstern","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17185v1"},{"title":"Judo: A User-Friendly Open-Source Package for Sampling-Based Model\n  Predictive Control","abstract":"Recent advancements in parallel simulation and successful robotic\napplications are spurring a resurgence in sampling-based model predictive\ncontrol. To build on this progress, however, the robotics community needs\ncommon tooling for prototyping, evaluating, and deploying sampling-based\ncontrollers. We introduce Judo, a software package designed to address this\nneed. To facilitate rapid prototyping and evaluation, Judo provides robust\nimplementations of common sampling-based MPC algorithms and standardized\nbenchmark tasks. It further emphasizes usability with simple but extensible\ninterfaces for controller and task definitions, asynchronous execution for\nstraightforward simulation-to-hardware transfer, and a highly customizable\ninteractive GUI for tuning controllers interactively. While written in Python,\nthe software leverages MuJoCo as its physics backend to achieve real-time\nperformance, which we validate across both consumer and server-grade hardware.\nCode at https:\/\/github.com\/bdaiinstitute\/judo.","authors":"Albert H. Li, Brandon Hung, Aaron D. Ames, Jiuguang Wang, Simon Le Cleac'h, Preston Culbertson","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17184v1"},{"title":"A Set-valued Impact Law Approach for Modeling and Analysis of Rigid\n  Contact Universal Joint with Clearance","abstract":"This study presents a dynamic model of a universal joint (U-Joint) with\nradial clearance, focusing on the rigid unilateral frictional contacts at the\ncrosspiece and yoke interfaces. Unlike previous models that neglect crosspiece\ninertia and interface friction, this work incorporates these effects using a\nset-valued impact law based on Signorini's condition with Coulomb friction,\ncapturing the complex non-smooth dynamics introduced by radial clearance.\nNumerical simulations of a 2 degrees-of-freedom (DOF) shaft system reveal the\ncritical influence of clearance on U-Joint dynamic behavior, including\nimpact-induced oscillations, quasi-periodic motion, and chaotic dynamics, which\nare essential for accurate driveline modeling and real-time control in\nautomotive, aerospace, and precision medical applications.","authors":"Junaid Ali, Gregory Shaver, Anil Bajaj","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17183v1"},{"title":"Variational Learning of Disentangled Representations","abstract":"Disentangled representations enable models to separate factors of variation\nthat are shared across experimental conditions from those that are\ncondition-specific. This separation is essential in domains such as biomedical\ndata analysis, where generalization to new treatments, patients, or species\ndepends on isolating stable biological signals from context-dependent effects.\nWhile extensions of the variational autoencoder (VAE) framework have been\nproposed to address this problem, they frequently suffer from leakage between\nlatent representations, limiting their ability to generalize to unseen\nconditions. Here, we introduce DISCoVeR, a new variational framework that\nexplicitly separates condition-invariant and condition-specific factors.\nDISCoVeR integrates three key components: (i) a dual-latent architecture that\nmodels shared and specific factors separately; (ii) two parallel\nreconstructions that ensure both representations remain informative; and (iii)\na novel max-min objective that encourages clean separation without relying on\nhandcrafted priors, while making only minimal assumptions. Theoretically, we\nshow that this objective maximizes data likelihood while promoting\ndisentanglement, and that it admits a unique equilibrium. Empirically, we\ndemonstrate that DISCoVeR achieves improved disentanglement on synthetic\ndatasets, natural images, and single-cell RNA-seq data. Together, these results\nestablish DISCoVeR as a principled approach for learning disentangled\nrepresentations in multi-condition settings.","authors":"Yuli Slavutsky, Ozgur Beker, David Blei, Bianca Dumitrascu","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17182v1"},{"title":"Fault Tolerance by Construction","abstract":"A key challenge in fault-tolerant quantum computing is synthesising and\noptimising circuits in a noisy environment, as traditional techniques often\nfail to account for the effect of noise on circuits. In this work, we propose a\nframework for designing fault-tolerant quantum circuits that are correct by\nconstruction. The framework starts with idealised specifications of\nfault-tolerant gadgets and refines them using provably sound basic\ntransformations.\n  To reason about manipulating circuits while preserving their error correction\nproperties, we define fault equivalence; two circuits are considered\nfault-equivalent if all undetectable faults on one circuit have a corresponding\nfault on the other. This guarantees that the effect of undetectable faults on\nboth circuits is the same. We argue that fault equivalence is a concept that is\nalready implicitly present in the literature. Many problems, such as state\npreparation and syndrome extraction, can be naturally expressed as finding an\nimplementable circuit that is fault-equivalent to an idealised specification.\n  To utilize fault equivalence in a computationally tractable manner, we adapt\nthe ZX calculus, a diagrammatic language for quantum computing. We restrict its\nrewrite system to not only preserve the underlying linear map but also fault\nequivalence, i.e. the circuit's behaviour under noise. Enabled by our\nframework, we verify, optimise and synthesise new and efficient circuits for\nsyndrome extraction and cat state preparation. We anticipate that fault\nequivalence can capture and unify different approaches in fault-tolerant\nquantum computing, paving the way for an end-to-end circuit compilation\nframework.","authors":"Benjamin Rodatz, Boldizs\u00e1r Po\u00f3r, Aleks Kissinger","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17181v1"},{"title":"CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models","abstract":"We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions\ndesigned to evaluate whether language models can determine if one statement\ncausally explains another. Each question present an assertion-reason pair and\nchallenge language models to distinguish between semantic relatedness and\ngenuine causal explanatory relationships. Through comprehensive evaluation of\n21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we\nidentify two fundamental findings. First, language models frequently confuse\nsemantic similarity with causality, relying on lexical and semantic overlap\ninstead of inferring actual causal explanatory relationships. Second, as\nparameter size increases, models tend to shift from being overly skeptical\nabout causal relationships to being excessively permissive in accepting them.\nDespite this shift, performance measured by the Matthews Correlation\nCoefficient plateaus at just 0.55, even for the best-performing models.Hence,\nCLEAR-3K provides a crucial benchmark for developing and evaluating genuine\ncausal reasoning in language models, which is an essential capability for\napplications that require accurate assessment of causal relationships.","authors":"Naiming Liu, Richard Baraniuk, Shashank Sonkar","year":"2025","url":"http:\/\/arxiv.org\/abs\/2506.17180v1"}]